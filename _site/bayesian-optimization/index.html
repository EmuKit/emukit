<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.5.0 --> <title>Bayesian Optimization | Emukit</title> <meta name="generator" content="Jekyll v3.7.4" /> <meta property="og:title" content="Bayesian Optimization" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Bayesian optimization is a sequential decision making approach to find the optimum of objective functions that are expensive to evaluate." /> <meta property="og:description" content="Bayesian optimization is a sequential decision making approach to find the optimum of objective functions that are expensive to evaluate." /> <link rel="canonical" href="http://localhost:4000/emukit/bayesian-optimization/" /> <meta property="og:url" content="http://localhost:4000/emukit/bayesian-optimization/" /> <meta property="og:site_name" content="Emukit" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2016-06-12T00:00:00+01:00" /> <meta name="twitter:card" content="summary" /> <meta name="twitter:site" content="@" /> <script type="application/ld+json"> {"url":"http://localhost:4000/emukit/bayesian-optimization/","headline":"Bayesian Optimization","dateModified":"2016-06-12T00:00:00+01:00","datePublished":"2016-06-12T00:00:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/emukit/bayesian-optimization/"},"description":"Bayesian optimization is a sequential decision making approach to find the optimum of objective functions that are expensive to evaluate.","@type":"BlogPosting","@context":"http://schema.org"}</script> <!-- End Jekyll SEO tag --> <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"> --> <link rel="stylesheet" href="/emukit/css/main.css"> <link rel="alternate" type="application/rss+xml" title="Emukit" href="http://localhost:4000/emukit/feed.xml"> <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"> </head> <body> <header class="site-header"> <nav class="navbar navbar-default"> <div class="container-fluid"> <!-- Brand and toggle get grouped for better mobile display --> <div class="navbar-header"> <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/emukit/">Emukit</a> </div> <!-- Collect the nav links, forms, and other content for toggling --> <div class="collapse navbar-collapse " id="bs-example-navbar-collapse-1"> <ul class="nav navbar-nav navbar-right"> <li><a href="/emukit/about/">About</a></li> <li><a href="/emukit/news/">News</a></li> <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Resources<span class="caret"></span></a> <ul class="dropdown-menu"> <li><a href="/emukit/installation/">Installation</a></li> <li><a href="/emukit/fiststeps/">First Steps</a></li> <li role="separator" class="divider"></li> <li><a href="/emukit/manual/">Reference Manual</a></li> <li><a href="/emukit/documentation/">Documentation</a></li> <li role="separator" class="divider"></li> <li><a href="/emukit/citation/">Citation</a></li> </ul> <li><a href="https://github.com/amzn/emukit">Github</a></li> </li> </ul> </div><!-- /.navbar-collapse --> </div><!-- /.container-fluid --> </nav> </header> <div class="container"> <div class="wrapper"> <div class="row"> <div class="col-md-8"> <article class="post" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header"> <h1 class="post-title" itemprop="name headline">Bayesian Optimization</h1> <p class="post-meta"><time datetime="2016-06-12T00:00:00+01:00" itemprop="datePublished">Jun 12, 2016</time></p> </header> <div class="post-content" itemprop="articleBody"> <p>Bayesian optimization is a sequential decision making approach to find the optimum of objective functions that are expensive to evaluate.</p> <p>Bayesian optimization (see <a href="#references-on-bayesian-optimization">[1]</a> for a review) focuses on global optimization problems where the objective is not directly accessible. This can be the case when evaluating the objective comes with a very high cost, <em>e. g.</em> training a large neural network in a large dataset, or because it is embodied in some physical process, <em>e. g.</em> optimizing a synthetic gene to over produce a protein in a cell. Other examples are problems in robotics, inference with intractable likelihoods, compilers optimization, etc.</p> <p>Given some function <script type="math/tex">f: \mathbb{X} \rightarrow \mathbb{R}</script> defined in a constrained input space <script type="math/tex">\mathbb{X}</script> the goal of is to find</p> <script type="math/tex; mode=display">x_{\star} = \operatorname*{arg\:min}_{x \in \mathbb{X}} f(x).</script> <p>For illustrative purposes of how to solve these problems with Emukit, we start by loading the <a href="https://www.sfu.ca/~ssurjano/branin.html">Branin function</a>. We define the input space to be <script type="math/tex">[-5,10]\times [0,15]</script>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">emukit.test_functions</span> <span class="kn">import</span> <span class="n">branin_function</span>
<span class="kn">from</span> <span class="nn">emukit.core</span> <span class="kn">import</span> <span class="n">ParameterSpace</span><span class="p">,</span> <span class="n">ContinuousParameter</span>

<span class="n">f</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">branin_function</span><span class="p">()</span>
<span class="n">parameter_space</span> <span class="o">=</span> <span class="n">ParameterSpace</span><span class="p">([</span><span class="n">ContinuousParameter</span><span class="p">(</span><span class="s">'x1'</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
                                  <span class="n">ContinuousParameter</span><span class="p">(</span><span class="s">'x2'</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">)])</span>
</code></pre></div></div> <p>In general cases we assume that the function <script type="math/tex">f</script> does not have explicit form and that it is expensive to evaluate. This means that to find the <script type="math/tex">x_{\star}</script> we’ll need to run a finite, and typically small, number of evaluations. Selecting these evaluations smartly is the key to approaching to the optimum with a minimal cost. This transform the original <em>optimization</em> problem in a sequence of <em>decision</em> problems (of where to select the best next location). In Bayesian optimization these problems are solved using principles of <em>statistical inference</em> and <em>decision theory</em>.</p> <p>How is it done? The first step is to define a prior probability measure on the objective <script type="math/tex">p(f)</script>. This measure captures our prior beliefs on <script type="math/tex">f</script> and can be either generic or it can be some sort of structural knowledge about the problem. Every time we collect a new data point in the form of pairs <script type="math/tex">(\textbf{x}_i,y_i)</script> the <em>prior</em> will be updated to a <em>posterior</em> <script type="math/tex">p(f|\mathcal{D}_n)</script> where <script type="math/tex">\mathcal{D}_n = \{(\textbf{x}_i, y_i)\}_{i=1}^n</script>, being <script type="math/tex">n</script> the number of available points. Following with our example, let’s start by collected 5 points at random and use them to train a Gaussian process <a href="#references-on-bayesian-optimization">[2]</a> with <a href="https://github.com/SheffieldML/GPy">GPy</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">emukit.experimental_design.model_free.random_design</span> <span class="kn">import</span> <span class="n">RandomDesign</span>
<span class="kn">from</span> <span class="nn">GPy.models</span> <span class="kn">import</span> <span class="n">GPRegression</span>
<span class="kn">from</span> <span class="nn">emukit.model_wrappers</span> <span class="kn">import</span> <span class="n">GPyModelWrapper</span>

<span class="n">design</span> <span class="o">=</span> <span class="n">RandomDesign</span><span class="p">(</span><span class="n">parameter_space</span><span class="p">)</span> <span class="c"># Collect random points</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">design</span><span class="o">.</span><span class="n">get_samples</span><span class="p">(</span><span class="n">num_data_points</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> 
<span class="n">Y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">model_gpy</span> <span class="o">=</span> <span class="n">GPRegression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span> <span class="c"># Train and wrap the model in Emukit</span>
<span class="n">model_emukit</span> <span class="o">=</span> <span class="n">GPyModelWrapper</span><span class="p">(</span><span class="n">model_gpy</span><span class="p">)</span>   
</code></pre></div></div> <p>The next step is to define an acquisition function <script type="math/tex">a: \mathbb{X} \rightarrow \mathbb{R}</script> able to quantify the utility of evaluating each point the input domain. The central idea of the acquisition function is to trade off the exploration in regions of the input space where the model is still uncertain and the exploitation of the model’s confidence about the good regions of the input space. There are a variety of acquisition functions in Emukit. In this example we use one of the most popular ones, the Expected improvement <a href="#references-on-bayesian-optimization">[3]</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">emukit.bayesian_optimization.acquisitions</span> <span class="kn">import</span> <span class="n">ExpectedImprovement</span> 

<span class="n">expected_improvement</span> <span class="o">=</span> <span class="n">ExpectedImprovement</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_emukit</span><span class="p">)</span>
</code></pre></div></div> <p>Given these ingredients, Bayesian optimization iterates the following three steps until it achieves a predefined stopping criterion.</p> <ol> <li>Find the next point to evaluate <script type="math/tex">x_{n+1}</script> by using a numerical solver maximize <script type="math/tex">a(x)</script>.</li> <li>Evaluate <script type="math/tex">f</script> <script type="math/tex">x_{n+1}</script>, obtain <script type="math/tex">y_{n+1}</script>. Add the new observation to the data, <script type="math/tex">D_{n+1} \leftarrow D_{n} \cup \{x_{n+1}, y_{n+1}\}</script>.</li> <li>Update the model using the currently available data.</li> </ol> <p>In Emukit, we first create the Bayesian optimization loop using the previously defined objects.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">emukit.bayesian_optimization.loops</span> <span class="kn">import</span> <span class="n">BayesianOptimizationLoop</span> 

<span class="n">bayesopt_loop</span> <span class="o">=</span> <span class="n">BayesianOptimizationLoop</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_emukit</span><span class="p">,</span>
                                         <span class="n">space</span> <span class="o">=</span> <span class="n">parameter_space</span><span class="p">,</span>
                                         <span class="n">acquisition</span> <span class="o">=</span> <span class="n">expected_improvement</span><span class="p">,</span>
                                         <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <p>The bach size is set to one in this example as we’ll collect evaluations sequentially but parallel evaluations are allowed. Once the loop is created we run it for some iterations, 20 in our example.</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from emukit.core.loop import FixedIterationsStoppingCondition 

stopping_condition = FixedIterationsStoppingCondition(i_max = 20)
bayesopt_loop.run_loop(f, stopping_condition)
</code></pre></div></div> <p>And that’s it! You can check the obtained the result looking into the state of the loop. Note that you can use other models, including those with multiple outputs, and acquisitions of your own in this loop.</p> <p>We’re always open to contributions! Please read our <a href="CONTRIBUTING.md">contribution guidelines</a> for more information. We are particularly interested in contributions regarding translations and tutorials.</p> <h4 id="references-on-bayesian-optimization">References on Bayesian optimization</h4> <ul> <li> <p>[1] Shahriari, B., Swersky, K., Wang, Z., Adams, R. P, de Freitas, N., (2016). <a href="https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf">Taking the Human Out of the Loop: A Review of Bayesian Optimization</a>. <em>Proceedings of the IEEE</em>, Vol.104, No.1, January 2016.</p> </li> <li> <p>[2] Rasmussen, C. E. and Williams, C. K. I., (2005). <a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf">Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning</a>. <em>The MIT Press</em>, 2005.</p> </li> <li> <p>[3] Jones, D. R., Schonlau, M., Welch, W. J., (1998). <a href="http://www.ressources-actuarielles.net/EXT/ISFA/1226.nsf/0/f84f7ac703bf5862c12576d8002f5259/$FILE/Jones98.pdf">Efficient Global Optimization of Expensive Black-Box Functions</a>. <em>Journal of Global Optimization</em>, 1998.</p> </li> </ul> </div> </article> <div class="row"> </div> <div class="row"> <ul class="pager"> <li><a class="next" href="/emukit/emukit-playground/">&laquo; Emukit-playground</a></li> <li><a class="previous" href="/emukit/multifidelity-emulation/">Multi-fidelity emulation &raquo;</a></li> </ul> </div> </div> <div class="col-md-4 mt20"> <div class="post-img"> <img width="600" src="/emukit/images/bayesian_optimization.jpeg" alt="Bayesian Optimization"> </div> <div class="mt10 recent"> <h2>Also in Emukit</h2> <ul> <li> <p><a href="/emukit/emukit-playground/">Emukit-playground</a></p> </li> <li> <p><a href="/emukit/multifidelity-emulation/">Multi-fidelity emulation</a></p> </li> <li> <p><a href="/emukit/experimental-design/">Experimental design</a></p> </li> </ul> </div> </div> </div> </div> </div> <footer> <div class="container"> <div class="row p20"> <div class="col-md-4 text-center mt25"> <a target="_blank" href="http://twitter.com/@emukitUQ"><li class="social twitter"><i class="fa fa-twitter-square"></i></li></a> <a target="_blank" href="https://github.com/amzn/emukit"><li class="social github"><i class="fa fa-github-square"></i></li></a> <a target="_blank" href="mailto:emukit-mailist@amazon.com"><li class="social email"><i class="fa fa-envelope"></i></li></a> </div> </div> </div> </footer> <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.2/jquery.min.js"></script> <script src="/emukit/js/bootstrap.min.js"></script> <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> <!-- Google Analytics Tracking code --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-83979019-1', 'auto'); ga('send', 'pageview'); </script> </body> </html>
