{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Fidelity Deep Gaussian process benchmark\n",
    "\n",
    "This notebook replicates the benchmark experiments from the paper:\n",
    "\n",
    "[Deep Gaussian Processes for Multi-fidelity Modeling (Kurt Cutajar, Mark Pullin, Andreas Damianou, Neil Lawrence, Javier Gonz√°lez)](https://arxiv.org/abs/1903.07320)\n",
    "\n",
    "Note that the code for one of the benchmark models in the paper, \"Deep Multi-fidelity Gaussian process\", is not publically available and so does not appear in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import emukit.examples.multi_fidelity_dgp\n",
    "\n",
    "from emukit.examples.multi_fidelity_dgp.baseline_model_wrappers import LinearAutoRegressiveModel, NonLinearAutoRegressiveModel, HighFidelityGp\n",
    "\n",
    "from emukit.core import ContinuousParameter\n",
    "from emukit.experimental_design.model_free.latin_design import LatinDesign\n",
    "from emukit.examples.multi_fidelity_dgp.multi_fidelity_deep_gp import MultiFidelityDeepGP\n",
    "\n",
    "from emukit.test_functions.multi_fidelity import (multi_fidelity_borehole_function, multi_fidelity_branin_function,\n",
    "                                                  multi_fidelity_park_function, multi_fidelity_hartmann_3d,\n",
    "                                                  multi_fidelity_currin_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for different benchmark functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Function = namedtuple('Function', ['name', 'y_scale', 'noise_level', 'do_x_scaling', 'num_data', 'fcn'])\n",
    "\n",
    "borehole = Function(name='borehole', y_scale=100, noise_level=[0.05, 0.1], do_x_scaling=True, num_data=[60, 5], \n",
    "                    fcn=multi_fidelity_borehole_function)\n",
    "branin = Function(name='branin', y_scale=1, noise_level=[0., 0., 0.], do_x_scaling=False, num_data=[80, 30, 10], \n",
    "                    fcn=multi_fidelity_branin_function)\n",
    "currin = Function(name='currin', y_scale=1, noise_level=[0., 0.], do_x_scaling=False, num_data=[12, 5], \n",
    "                    fcn=multi_fidelity_currin_function)\n",
    "park = Function(name='park', y_scale=1, noise_level=[0., 0.], do_x_scaling=False, num_data=[30, 5], \n",
    "                    fcn=multi_fidelity_park_function)\n",
    "hartmann_3d = Function(name='hartmann', y_scale=1, noise_level=[0., 0., 0.], do_x_scaling=False, num_data=[80, 40, 20], \n",
    "                    fcn=multi_fidelity_hartmann_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to repeat test across different random seeds.\n",
    "\n",
    "def do_benchmark(fcn_tuple):\n",
    "    metrics = dict()\n",
    "\n",
    "    # Some random seeds to use\n",
    "    seeds = [123, 184, 202, 289, 732]\n",
    "\n",
    "    for i, seed in enumerate(seeds):\n",
    "        run_name = str(seed) + str(fcn_tuple.num_data)\n",
    "        metrics[run_name] = test_function(fcn_tuple, seed)\n",
    "        print('After ' + str(i+1) + ' runs of ' + fcn_tuple.name)\n",
    "        print_metrics(metrics)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print metrics as table \n",
    "def print_metrics(metrics):\n",
    "    model_names = list(list(metrics.values())[0].keys())\n",
    "    metric_names = ['r2', 'mnll', 'rmse']\n",
    "    table = PrettyTable(['model'] + metric_names)\n",
    "\n",
    "    for name in model_names:\n",
    "        mean = []\n",
    "        for metric_name in metric_names:\n",
    "            mean.append(np.mean([metric[name][metric_name] for metric in metrics.values()]))\n",
    "        table.add_row([name] + mean)\n",
    "\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(fcn, seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    x_test, y_test, X, Y = generate_data(fcn, 1000)\n",
    "\n",
    "    mf_dgp_fix_lf_mean = MultiFidelityDeepGP(X, Y, n_iter=5000)\n",
    "    mf_dgp_fix_lf_mean.name = 'mf_dgp_fix_lf_mean'\n",
    "\n",
    "    models = [HighFidelityGp(X, Y), LinearAutoRegressiveModel(X, Y), NonLinearAutoRegressiveModel(X, Y), mf_dgp_fix_lf_mean]\n",
    "    return benchmark_models(models, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_models(models, x_test, y_test):\n",
    "    metrics = dict()\n",
    "    for model in models:\n",
    "        model.optimize()\n",
    "        y_mean, y_var = model.predict(x_test)\n",
    "        metrics[model.name] = calculate_metrics(y_test, y_mean, y_var)\n",
    "        print('+ ######################## +')\n",
    "        print(model.name, 'r2', metrics[model.name]['r2'])\n",
    "        print('+ ######################## + ')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(fcn_tuple, n_test_points):\n",
    "    \"\"\"\n",
    "    Generates train and test data for\n",
    "    \"\"\"\n",
    "    \n",
    "    do_x_scaling = fcn_tuple.do_x_scaling\n",
    "    fcn, space = fcn_tuple.fcn()\n",
    "    \n",
    "    # Generate training data\n",
    "    latin = LatinDesign(space)\n",
    "    X = [latin.get_samples(n) for n in fcn_tuple.num_data]\n",
    "    \n",
    "    # Scale X if required\n",
    "    if do_x_scaling:\n",
    "        scalings = X[0].std(axis=0)\n",
    "    else:\n",
    "        scalings = np.ones(X[0].shape[1])\n",
    "        \n",
    "    for x in X:\n",
    "        x /= scalings\n",
    "    \n",
    "    Y = []\n",
    "    for i, x in enumerate(X):\n",
    "        Y.append(fcn.f[i](x * scalings))\n",
    "    \n",
    "    y_scale = fcn_tuple.y_scale\n",
    "    \n",
    "    # scale y and add noise if required\n",
    "    noise_levels = fcn_tuple.noise_level\n",
    "    for y, std_noise in zip(Y, noise_levels):\n",
    "        y /= y_scale + std_noise * np.random.randn(y.shape[0], 1)\n",
    "    \n",
    "    # Generate test data\n",
    "    x_test = latin.get_samples(n_test_points)\n",
    "    x_test /= scalings\n",
    "    y_test = fcn.f[-1](x_test * scalings)\n",
    "    y_test /= y_scale\n",
    "\n",
    "    i_highest_fidelity = (len(fcn_tuple.num_data) - 1) * np.ones((x_test.shape[0], 1))\n",
    "    x_test = np.concatenate([x_test, i_highest_fidelity], axis=1)\n",
    "    print(X[1].shape)\n",
    "    return x_test, y_test, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_test, y_mean_prediction, y_var_prediction):\n",
    "    # R2\n",
    "    r2 = r2_score(y_test, y_mean_prediction)\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_mean_prediction))\n",
    "    # Test log likelihood\n",
    "    mnll = -np.sum(scipy.stats.norm.logpdf(y_test, loc=y_mean_prediction, scale=np.sqrt(y_var_prediction)))/len(y_test)\n",
    "    return {'r2': r2, 'rmse': rmse, 'mnll': mnll}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "Optimization restart 1/10, f = 3.9209291518359493\n",
      "Optimization restart 2/10, f = 3.9207719547014026\n",
      "Optimization restart 3/10, f = 3.9208444850857456\n",
      "Optimization restart 4/10, f = 11.73929839025675\n",
      "Optimization restart 5/10, f = 3.9207637776647255\n",
      "Optimization restart 6/10, f = 4.050159266188403\n",
      "Optimization restart 7/10, f = 3.920765267661852\n",
      "Optimization restart 8/10, f = 4.672538790017487\n",
      "Optimization restart 9/10, f = 3.9207648050244535\n",
      "Optimization restart 10/10, f = 3.9207635147752224\n",
      "+ ######################## +\n",
      "hf_gp r2 0.8943636075476714\n",
      "+ ######################## + \n",
      "Optimization restart 1/10, f = 4.132142401567391\n",
      "Optimization restart 2/10, f = 5.884477714950112\n",
      "Optimization restart 3/10, f = 5.884477731070794\n",
      "Optimization restart 4/10, f = 5.884477715848345\n",
      "Optimization restart 5/10, f = 4.124559747242914\n",
      "Optimization restart 6/10, f = 4.122939203203559\n",
      "Optimization restart 7/10, f = 4.120672169954153\n",
      "Optimization restart 8/10, f = 19.98593024058279\n",
      "Optimization restart 9/10, f = 7.437534821000899\n",
      "Optimization restart 10/10, f = 5.884477756883458\n",
      "Optimization restart 1/10, f = 4.1206721693824395\n",
      "Optimization restart 2/10, f = 10.118267417727727\n",
      "Optimization restart 3/10, f = 10.04706444369329\n",
      "Optimization restart 4/10, f = 10.118267401743793\n",
      "Optimization restart 5/10, f = 5.885853528430937\n",
      "Optimization restart 6/10, f = 44.85720024294169\n",
      "Optimization restart 7/10, f = 10.11827497017242\n",
      "Optimization restart 8/10, f = 5.885272690672226\n",
      "Optimization restart 9/10, f = 9.955014597801249\n",
      "Optimization restart 10/10, f = 10.118267403324024\n",
      "+ ######################## +\n",
      "ar1 r2 0.9099288087983146\n",
      "+ ######################## + \n",
      "Optimization restart 1/10, f = 3.9884334705131046\n",
      "Optimization restart 2/10, f = 3.988433470408676\n",
      "Optimization restart 3/10, f = 3.988433470417908\n",
      "Optimization restart 4/10, f = 3.988433470833\n",
      "Optimization restart 5/10, f = 3.988433470550774\n",
      "Optimization restart 6/10, f = 3.9884334704055995\n",
      "Optimization restart 7/10, f = 3.9884334704161715\n",
      "Optimization restart 8/10, f = 3.988433470448168\n",
      "Optimization restart 9/10, f = 3.988433470400551\n",
      "Optimization restart 10/10, f = 18.661180811485032\n",
      "Warning - optimization restart 1/10 failed\n",
      "Optimization restart 2/10, f = 4.389714004148407\n",
      "Optimization restart 3/10, f = 3.920809798172703\n",
      "Warning - optimization restart 4/10 failed\n",
      "Optimization restart 5/10, f = 4.389930236330437\n",
      "Optimization restart 6/10, f = 3.920784079568272\n",
      "Optimization restart 7/10, f = 4.217792341768034\n",
      "Optimization restart 8/10, f = 3.920946498035531\n",
      "Optimization restart 9/10, f = 3.9216248048882125\n",
      "Optimization restart 10/10, f = 3.9207660815517156\n",
      "+ ######################## +\n",
      "nargp r2 0.8943638965925069\n",
      "+ ######################## + \n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "metrics.append(do_benchmark(currin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (metric) in zip(metrics):\n",
    "    print(fcn_name)\n",
    "    print_metrics(metric[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emukit_devel]",
   "language": "python",
   "name": "conda-env-emukit_devel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
